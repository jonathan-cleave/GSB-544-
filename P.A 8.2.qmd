---
title: Palmer Penguins Modeling
jupyter: python3
format:
  html:
    embed-resources: true
    theme: Zephyr
---


Import the Palmer Penguins dataset and print out the first few rows.

Suppose we want to predict `species` using the other variables in the dataset.

**Dummify** all variables that require this.

```{python}
# Code Here
import pandas as pd
import numpy as np
from sklearn.pipeline import Pipeline
from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier
from sklearn.tree import DecisionTreeRegressor
from sklearn.tree import DecisionTreeClassifier
from palmerpenguins import load_penguins
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.compose import make_column_selector, ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder, label_binarize
from sklearn.tree import plot_tree
from plotnine import *
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import cross_validate, KFold
from sklearn.model_selection import train_test_split, KFold, cross_validate
from sklearn.metrics import *
import matplotlib.pyplot as plt
from sklearn.metrics import classification_report, accuracy_score, RocCurveDisplay
import math
```

```{python}
penguins = load_penguins()
penguins = penguins.dropna()
penguins
```

```{python}
X = penguins.drop(["species"],axis=1)
y = penguins["species"]


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, stratify=y, random_state=321)
```

```{python}
#KNN 2 and 5
ct_knn = ColumnTransformer(
  [
    ("dummify",
    OneHotEncoder(sparse_output = False, handle_unknown='ignore'),
    make_column_selector(dtype_include=object)),
    ("standardize",
    StandardScaler(),
    make_column_selector(dtype_include=np.number))
  ],
  remainder="drop"
)

k_neighbors_pipeline2 = Pipeline(
  [
    ("preprocessing", ct_knn),
    ("clf", KNeighborsClassifier(n_neighbors=2))
  ]
)

k_neighbors_pipeline5 = Pipeline(
  [
    ("preprocessing", ct_knn),
    ("clf", KNeighborsClassifier(n_neighbors=5))
  ]
)
```

```{python}


decision_pipeline2 = Pipeline(
  [
    ("preprocessing", ct_knn),
    ("clf", DecisionTreeClassifier(max_depth=2))
  ]
)


decision_pipeline5 = Pipeline(
  [
    ("preprocessing", ct_knn),
    ("clf", DecisionTreeClassifier(max_depth=5))
  ]
)
```

Let's use the other variables to predict `species`. Prepare your data and fit the following models on the entire dataset:

* Two kNN models (for different values of K)
* Two decision tree models (for different complexities of trees)

Compute the following, for each of your models, on test data. Keep in mind that you may need to stratify your creation of the training and test data.

* Confusion matrix
* Overall Accuracy
* Precision, Recall, AUC, and F1-score for each species

Create one ROC plot for the species of your choice.

```{python}
models = {
    "KNN=2":  k_neighbors_pipeline2,
    "KNN=5":  k_neighbors_pipeline5,
    "DT=2":   decision_pipeline2,
    "DT=5":   decision_pipeline5,
}
```

```{python}
# confusion matrixices
classes = list(y.unique())

n = len(models)
cols = 2 if n > 1 else 1
rows = math.ceil(n / cols)

fig, axes = plt.subplots(rows, cols, figsize=(5*cols, 4*rows), squeeze=False)
axes = axes.ravel()

for ax, (name, mdl) in zip(axes, models.items()):
    mdl.fit(X_train, y_train)
    ConfusionMatrixDisplay.from_estimator(
        mdl, X_test, y_test,
        labels=classes,
        display_labels=classes,
        cmap=plt.cm.Blues,
        colorbar=False,
        ax=ax
    )
    ax.set_title(name)

for k in range(len(models), len(axes)):
    fig.delaxes(axes[k])

fig.tight_layout()
plt.show()
```

```{python}
# Classification report with Precision, Specificity Recall, Accuracy and F1 for all species and models

for name, model in models.items():
  model.fit(X_train, y_train)
  y_pred = model.predict(X_test)
  print(name)
  print(classification_report(y_test, y_pred, target_names=y.unique(), digits=4))
```

```{python}
#Auc scores
fitted = {name: mdl.fit(X_train, y_train) for name, mdl in models.items()}

rows = []
for name, mdl in fitted.items():

    testPredictionProbs = mdl.predict_proba(X_test)

    est_classes = list(mdl.named_steps.values())[-1].classes_

    row = {"Model": name}
    for target_class in classes:
        target_class_idx = np.where(est_classes == target_class)[0][0]
        y_true_binary = (y_test == target_class).astype(int)
        y_score_target_class = testPredictionProbs[:, target_class_idx]
        row[target_class] = roc_auc_score(y_true_binary, y_score_target_class)
    rows.append(row)

auc_df = pd.DataFrame(rows).set_index("Model")[list(classes)]
auc_df.round(4)
```

```{python}
#Roc curve for Adelie
target_class = y.unique()[0]

plt.figure(figsize=(7,6))
ax = plt.gca()

for name, model in models.items():
    model.fit(X_train, y_train)


    proba = model.predict_proba(X_test)
    classes = model.named_steps["clf"].classes_
    j = np.where(classes == target_class)[0][0]
    y_score = proba[:, j]

    y_true = (y_test == target_class).astype(int)

    RocCurveDisplay.from_predictions(y_true, y_score, name=name, ax=ax)

ax.plot([0,1], [0,1], "--", lw=1)
ax.set_title(f"ROC â€” {target_class}")
plt.tight_layout(); plt.show()
```

